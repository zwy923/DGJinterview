import { useState, useRef, useEffect } from "react";
import { connectASRWebSocket, startSystemAudio, stopSystemAudio, stopWebSocket } from "../api/websocket";
import AudioTestPanel from "./AudioTestPanel";
import AudioLevelMeter from "./AudioLevelMeter";
import { AudioWorkletManager } from "../audio/audioWorkletManager";

interface Props {
  onUserText: (text: string, isPartial?: boolean) => void;
  onInterviewerText: (text: string, isPartial?: boolean) => void;
  sessionId?: string; // ä¼šè¯ID
}

export default function AudioController({ onUserText, onInterviewerText, sessionId = "default" }: Props) {
  const [recording, setRecording] = useState(false);
  const [error, setError] = useState<string>("");
  const [connectionStatus, setConnectionStatus] = useState<string>("æœªè¿æ¥");
  const [systemAudioEnabled, setSystemAudioEnabled] = useState(false);
  const [showTestPanel, setShowTestPanel] = useState(false);
  const [systemStream, setSystemStream] = useState<MediaStream | null>(null);
  // ç”¨æˆ·éº¦å…‹é£ç›¸å…³
  const userWsRef = useRef<WebSocket | null>(null);
  const userStreamRef = useRef<MediaStream | null>(null);
  const userWorkletManagerRef = useRef<AudioWorkletManager | null>(null);
  const userProcessorRef = useRef<ScriptProcessorNode | null>(null); // é™çº§æ¨¡å¼ä½¿ç”¨
  const userAudioContextRef = useRef<AudioContext | null>(null); // é™çº§æ¨¡å¼ä½¿ç”¨
  
  // ç³»ç»ŸéŸ³é¢‘WebSocketè¿æ¥
  const systemWsRef = useRef<WebSocket | null>(null);

  // å¯åŠ¨ç”¨æˆ·éº¦å…‹é£å½•éŸ³
  const startUserAudio = async () => {
    try {
      console.log("ğŸ¤ å¼€å§‹æ•è·ç”¨æˆ·éº¦å…‹é£...");
      
      // è·å–éº¦å…‹é£æƒé™ï¼ˆä¸æµ‹è¯•ä¿æŒä¸€è‡´ï¼‰
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true // ä¸æµ‹è¯•ä¿æŒä¸€è‡´ï¼Œä½¿ç”¨ AGC
        }
      });
      
      userStreamRef.current = stream;
      
      // åˆ›å»ºWebSocketè¿æ¥ï¼ˆæ–°æ¥å£ï¼š/ws/audio/{session_id}/micï¼‰
      userWsRef.current = connectASRWebSocket(sessionId, "mic", {
        onFinal: (text) => {
          onUserText(text, false);
        },
        onPartial: (text) => {
          // éƒ¨åˆ†ç»“æœç”¨äºå®æ—¶æ˜¾ç¤ºï¼ˆæ–œä½“æˆ–ç°è‰²ï¼‰
          onUserText(text, true);
        },
        onInfo: (text) => {
          console.log("[mic] Info:", text);
          if (text.includes("connected")) {
            setConnectionStatus("å·²è¿æ¥ - è¯†åˆ«ä¸­");
          }
        },
        onError: (text) => {
          console.error("[mic] Error:", text);
          setError(text);
        }
      });
      
      // ä½¿ç”¨ AudioWorklet æ›¿ä»£ ScriptProcessor
      // å¦‚æœ AudioWorklet åŠ è½½å¤±è´¥ï¼Œå¯ä»¥é™çº§åˆ° ScriptProcessor
      let workletManager: AudioWorkletManager | null = null;
      try {
        workletManager = new AudioWorkletManager();
        await workletManager.initialize(stream, {
        onAudioFrame: (data, metadata) => {
          // å‘é€éŸ³é¢‘å¸§ï¼ˆå¸¦å…ƒæ•°æ®ï¼‰
          if (userWsRef.current?.readyState === WebSocket.OPEN) {
            try {
              // åˆ›å»ºå¸¦å…ƒæ•°æ®çš„æ¶ˆæ¯
              // æ ¼å¼ï¼šseq(4) + t0(8) + sr(4) + channels(1) + frameCount(4) + rms(4) = 25å­—èŠ‚
              // ä½¿ç”¨ 32 å­—èŠ‚å¯¹é½ï¼Œä¾¿äºåç»­æ‰©å±•
              const header = new ArrayBuffer(32);
              const view = new DataView(header);
              let offset = 0;
              view.setUint32(offset, metadata.seq, true); offset += 4;
              view.setFloat64(offset, metadata.t0, true); offset += 8;
              view.setUint32(offset, metadata.sr, true); offset += 4;
              view.setUint8(offset, metadata.channels); offset += 1;
              view.setUint32(offset, metadata.frameCount, true); offset += 4;
              if (metadata.rms !== undefined) {
                view.setFloat32(offset, metadata.rms, true); offset += 4;
              }
              // offset ç°åœ¨åº”è¯¥æ˜¯ 25ï¼Œå‰©ä½™ 7 å­—èŠ‚ä¸º paddingï¼ˆè‡ªåŠ¨ä¸º 0ï¼‰
              
              // åˆå¹¶ header å’ŒéŸ³é¢‘æ•°æ®
              const combined = new Uint8Array(header.byteLength + data.byteLength);
              combined.set(new Uint8Array(header), 0);
              combined.set(new Uint8Array(data), header.byteLength);
              
              // æ£€æŸ¥ WebSocket ç¼“å†²çŠ¶æ€ï¼ˆé¿å…é˜»å¡ï¼‰
              if (userWsRef.current.bufferedAmount > 1024 * 1024) { // 1MB
                console.warn('[Audio] WebSocket buffer full, dropping frame');
                return;
              }
              
              userWsRef.current.send(combined.buffer);
            } catch (error) {
              console.error('[Audio] Failed to send audio frame:', error);
              // ä¸æŠ›å‡ºé”™è¯¯ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€å¸§
            }
          }
        },
        onError: (error) => {
          console.error("AudioWorklet error:", error);
          setError(`éŸ³é¢‘å¤„ç†é”™è¯¯: ${error.message}`);
        }
      });
      
      userWorkletManagerRef.current = workletManager;
      console.log("âœ… ç”¨æˆ·éº¦å…‹é£å·²å¯åŠ¨ï¼ˆAudioWorkletï¼‰");
      } catch (workletError) {
        console.warn("AudioWorklet åˆå§‹åŒ–å¤±è´¥ï¼Œé™çº§åˆ° ScriptProcessorï¼ˆä¸æµ‹è¯•é€»è¾‘ä¸€è‡´ï¼‰:", workletError);
        // é™çº§åˆ° ScriptProcessorï¼ˆä¸æµ‹è¯•é€»è¾‘å®Œå…¨ä¸€è‡´ï¼‰
        const audioContext = new AudioContext({ sampleRate: 16000 });
        userAudioContextRef.current = audioContext;
        const source = audioContext.createMediaStreamSource(stream);
        const processor = audioContext.createScriptProcessor(4096, 1, 1);
        userProcessorRef.current = processor;
        
        // åˆ›å»ºé™éŸ³çš„ GainNodeï¼ˆScriptProcessor å¿…é¡»è¿æ¥è¾“å‡ºæ‰èƒ½å·¥ä½œï¼‰
        const silentGain = audioContext.createGain();
        silentGain.gain.value = 0;
        processor.connect(silentGain);
        silentGain.connect(audioContext.destination);
        
        processor.onaudioprocess = (event) => {
          if (userWsRef.current?.readyState === WebSocket.OPEN) {
            try {
              const inputData = event.inputBuffer.getChannelData(0);
              // è½¬æ¢ä¸º16ä½PCMï¼ˆä¸æµ‹è¯•é€»è¾‘ä¸€è‡´ï¼‰
              const pcmData = new Int16Array(inputData.length);
              for (let i = 0; i < inputData.length; i++) {
                pcmData[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32768));
              }
              // ç›´æ¥å‘é€ PCM æ•°æ®ï¼ˆæ— å…ƒæ•°æ®å¤´ï¼Œä¸æµ‹è¯•ä¸€è‡´ï¼‰
              userWsRef.current.send(pcmData.buffer);
            } catch (error) {
              console.error('[Audio] ScriptProcessor send error:', error);
            }
          }
        };
        
        source.connect(processor);
        userWorkletManagerRef.current = null; // æ ‡è®°ä½¿ç”¨ ScriptProcessor
        console.log("âœ… ç”¨æˆ·éº¦å…‹é£å·²å¯åŠ¨ï¼ˆScriptProcessor é™çº§æ¨¡å¼ï¼Œä¸æµ‹è¯•ä¸€è‡´ï¼‰");
      }
      
    } catch (err) {
      console.error("ç”¨æˆ·éº¦å…‹é£å¯åŠ¨å¤±è´¥:", err);
      throw new Error("æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®");
    }
  };

  // å¯åŠ¨ç³»ç»ŸéŸ³é¢‘ï¼ˆé€šè¿‡åç«¯ï¼‰
  const startSystemAudioCapture = async () => {
    try {
      console.log("ğŸ”Š å¯åŠ¨åç«¯ç³»ç»ŸéŸ³é¢‘æ•è·...");
      
      // åˆ›å»ºç³»ç»ŸéŸ³é¢‘WebSocketè¿æ¥ï¼ˆæ–°æ¥å£ï¼š/ws/audio/{session_id}/sysï¼‰
      systemWsRef.current = connectASRWebSocket(sessionId, "sys", {
        onFinal: (text) => {
          onInterviewerText(text, false);
        },
        onPartial: (text) => {
          // éƒ¨åˆ†ç»“æœç”¨äºå®æ—¶æ˜¾ç¤º
          onInterviewerText(text, true);
        },
        onInfo: (text) => {
          console.log("[sys] Info:", text);
        },
        onError: (text) => {
          console.error("[sys] Error:", text);
          setError(text);
        }
      });
      
      // ç­‰å¾…WebSocketè¿æ¥å»ºç«‹
      await new Promise((resolve, reject) => {
        if (systemWsRef.current) {
          systemWsRef.current.onopen = resolve;
          systemWsRef.current.onerror = reject;
          // è®¾ç½®è¶…æ—¶
          setTimeout(() => reject(new Error("è¿æ¥è¶…æ—¶")), 5000);
        }
      });
      
      // å¯åŠ¨åç«¯ç³»ç»ŸéŸ³é¢‘æ•è·
      const success = await startSystemAudio(systemWsRef.current!);
      if (!success) {
        throw new Error("åç«¯ç³»ç»ŸéŸ³é¢‘å¯åŠ¨å¤±è´¥");
      }
      
      console.log("âœ… ç³»ç»ŸéŸ³é¢‘å·²å¯åŠ¨");
      
      // ä¸ºäº†æ˜¾ç¤ºéŸ³é¢‘çº§åˆ«ï¼Œæˆ‘ä»¬ä¹Ÿéœ€è¦è·å–ç³»ç»ŸéŸ³é¢‘æµ
      try {
        const systemStream = await navigator.mediaDevices.getDisplayMedia({
          audio: true,
          video: false
        });
        setSystemStream(systemStream);
      } catch (err) {
        console.warn("æ— æ³•è·å–ç³»ç»ŸéŸ³é¢‘æµç”¨äºæ˜¾ç¤º:", err);
      }
      
    } catch (err) {
      console.error("ç³»ç»ŸéŸ³é¢‘å¯åŠ¨å¤±è´¥:", err);
      throw new Error("ç³»ç»ŸéŸ³é¢‘å¯åŠ¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥åç«¯æœåŠ¡");
    }
  };

  // å¯åŠ¨éº¦å…‹é£å½•éŸ³
  const startMic = async () => {
    try {
      setError("");
      console.log("ğŸ¤ å¼€å§‹æ•è·éº¦å…‹é£...");
      
      await startUserAudio();
      
      setConnectionStatus("å·²è¿æ¥ - è¯†åˆ«ä¸­");
      setRecording(true);
      
    } catch (err) {
      console.error("éº¦å…‹é£å¯åŠ¨å¤±è´¥:", err);
      setError(err instanceof Error ? err.message : "éº¦å…‹é£å¯åŠ¨å¤±è´¥");
    }
  };

  // åœæ­¢éº¦å…‹é£å½•éŸ³
  const stopMic = () => {
    console.log("ğŸ›‘ åœæ­¢éº¦å…‹é£å½•éŸ³");
    
    // åœæ­¢ç”¨æˆ·éŸ³é¢‘å¤„ç†ï¼ˆAudioWorklet æˆ– ScriptProcessorï¼‰
    if (userWorkletManagerRef.current) {
      userWorkletManagerRef.current.stop();
      userWorkletManagerRef.current = null;
    }
    
    // æ¸…ç† ScriptProcessor é™çº§æ¨¡å¼
    if (userProcessorRef.current) {
      userProcessorRef.current.disconnect();
      userProcessorRef.current = null;
    }
    
    if (userAudioContextRef.current) {
      userAudioContextRef.current.close();
      userAudioContextRef.current = null;
    }
    
    if (userStreamRef.current) {
      userStreamRef.current.getTracks().forEach(track => track.stop());
      userStreamRef.current = null;
    }
    
    if (userWsRef.current) {
      stopWebSocket(userWsRef.current);
      userWsRef.current = null;
    }
    
    setRecording(false);
    if (!systemAudioEnabled) {
      setConnectionStatus("æœªè¿æ¥");
    }
  };

  // å¯åŠ¨ç³»ç»ŸéŸ³é¢‘
  const startSystem = async () => {
    try {
      setError("");
      console.log("ğŸ”Š å¯åŠ¨ç³»ç»ŸéŸ³é¢‘...");
      
      await startSystemAudioCapture();
      setSystemAudioEnabled(true);
      console.log("âœ… ç³»ç»ŸéŸ³é¢‘å·²å¯åŠ¨");
      
    } catch (err) {
      console.error("ç³»ç»ŸéŸ³é¢‘å¯åŠ¨å¤±è´¥:", err);
      setError(err instanceof Error ? err.message : "ç³»ç»ŸéŸ³é¢‘å¯åŠ¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥åç«¯æœåŠ¡");
    }
  };

  // åœæ­¢ç³»ç»ŸéŸ³é¢‘
  const stopSystem = () => {
    console.log("ğŸ›‘ åœæ­¢ç³»ç»ŸéŸ³é¢‘");
    
    if (systemWsRef.current) {
      stopSystemAudio(systemWsRef.current).then(() => {
        stopWebSocket(systemWsRef.current!);
        systemWsRef.current = null;
      });
    }
    
    if (systemStream) {
      systemStream.getTracks().forEach(track => track.stop());
      setSystemStream(null);
    }
    
    setSystemAudioEnabled(false);
    if (!recording) {
      setConnectionStatus("æœªè¿æ¥");
    }
  };



  // æ¸…ç†èµ„æº
  useEffect(() => {
    return () => {
      if (recording) {
        stopMic();
      }
      if (systemAudioEnabled) {
        stopSystem();
      }
    };
  }, []);

  return (
    <div className="audio-controller" style={{ marginTop: "1rem" }}>
      {error && (
        <div style={{ 
          color: '#ef4444', 
          fontSize: '0.875rem', 
          marginBottom: '0.5rem',
          padding: '0.5rem',
          background: 'rgba(239, 68, 68, 0.1)',
          borderRadius: '0.375rem',
          border: '1px solid rgba(239, 68, 68, 0.3)'
        }}>
          {error}
        </div>
      )}
      
      <div style={{ 
        display: 'flex', 
        gap: '0.75rem', 
        marginBottom: '1rem', 
        flexWrap: 'wrap',
        justifyContent: 'center',
        alignItems: 'center'
      }}>
        {/* éº¦å…‹é£å½•éŸ³æŒ‰é’® */}
        <button 
          onClick={recording ? stopMic : startMic}
          style={{ 
            background: recording 
              ? 'linear-gradient(135deg, #ef4444, #dc2626)' 
              : 'linear-gradient(135deg, #10b981, #059669)',
            color: 'white',
            border: 'none',
            borderRadius: '0.5rem',
            padding: '0.75rem 1.5rem',
            cursor: 'pointer',
            fontSize: '0.875rem',
            fontWeight: '600',
            minWidth: '120px',
            transition: 'all 0.2s ease',
            boxShadow: '0 2px 4px rgba(0, 0, 0, 0.1)'
          }}
          onMouseEnter={(e) => {
            e.currentTarget.style.transform = 'translateY(-1px)';
            e.currentTarget.style.boxShadow = '0 4px 8px rgba(0, 0, 0, 0.15)';
          }}
          onMouseLeave={(e) => {
            e.currentTarget.style.transform = 'translateY(0)';
            e.currentTarget.style.boxShadow = '0 2px 4px rgba(0, 0, 0, 0.1)';
          }}
        >
          {recording ? 'â¹ åœæ­¢éº¦å…‹é£' : 'ğŸ¤ å¼€å§‹éº¦å…‹é£'}
        </button>

        {/* ç³»ç»ŸéŸ³é¢‘æŒ‰é’® */}
        <button 
          onClick={systemAudioEnabled ? stopSystem : startSystem}
          style={{ 
            background: systemAudioEnabled 
              ? 'linear-gradient(135deg, #ef4444, #dc2626)' 
              : 'linear-gradient(135deg, #8b5cf6, #7c3aed)',
            color: 'white',
            border: 'none',
            borderRadius: '0.5rem',
            padding: '0.75rem 1.5rem',
            cursor: 'pointer',
            fontSize: '0.875rem',
            fontWeight: '600',
            minWidth: '120px',
            transition: 'all 0.2s ease',
            boxShadow: '0 2px 4px rgba(0, 0, 0, 0.1)'
          }}
          onMouseEnter={(e) => {
            e.currentTarget.style.transform = 'translateY(-1px)';
            e.currentTarget.style.boxShadow = '0 4px 8px rgba(0, 0, 0, 0.15)';
          }}
          onMouseLeave={(e) => {
            e.currentTarget.style.transform = 'translateY(0)';
            e.currentTarget.style.boxShadow = '0 2px 4px rgba(0, 0, 0, 0.1)';
          }}
        >
          {systemAudioEnabled ? 'â¹ åœæ­¢ç³»ç»ŸéŸ³é¢‘' : 'ğŸ”Š å¼€å§‹ç³»ç»ŸéŸ³é¢‘'}
        </button>
      </div>
      
      {/* å®æ—¶éŸ³é¢‘ç›‘æ§ */}
      {(recording || systemAudioEnabled) && (
        <div style={{
          backgroundColor: '#f9fafb',
          padding: '1rem',
          borderRadius: '0.5rem',
          marginTop: '1rem',
          border: '1px solid #e5e7eb'
        }}>
          <div style={{ 
            fontSize: '0.875rem', 
            fontWeight: '600', 
            marginBottom: '0.75rem',
            color: '#374151',
            textAlign: 'center'
          }}>
            ğŸ“Š å®æ—¶éŸ³é¢‘ç›‘æ§
          </div>
          
          {recording && (
            <AudioLevelMeter 
              stream={userStreamRef.current}
              label="ğŸ¤ éº¦å…‹é£"
              color="#10b981"
              isActive={recording}
            />
          )}
          
          {systemAudioEnabled && (
            <AudioLevelMeter 
              stream={systemStream}
              label="ğŸ”Š ç³»ç»ŸéŸ³é¢‘"
              color="#8b5cf6"
              isActive={systemAudioEnabled}
            />
          )}
        </div>
      )}
      
      <div style={{ 
        fontSize: '0.75rem', 
        color: '#a1a1aa', 
        marginTop: '0.5rem',
        textAlign: 'center'
      }}>
        <div style={{ marginBottom: '0.25rem' }}>
          çŠ¶æ€: <span style={{ 
            color: connectionStatus.includes('å·²è¿æ¥') ? '#10b981' : 
                   connectionStatus.includes('é”™è¯¯') ? '#ef4444' : '#f59e0b'
          }}>
            {connectionStatus}
          </span>
        </div>
        <div style={{ marginBottom: '0.25rem' }}>
          éº¦å…‹é£: <span style={{ color: recording ? '#10b981' : '#f59e0b' }}>
            {recording ? 'âœ“ å·²å¯ç”¨' : 'âœ— æœªå¯ç”¨'}
          </span>
        </div>
        <div style={{ marginBottom: '0.25rem' }}>
          ç³»ç»ŸéŸ³é¢‘: <span style={{ 
            color: systemAudioEnabled ? '#10b981' : '#f59e0b'
          }}>
            {systemAudioEnabled ? 'âœ“ å·²å¯ç”¨' : 'âœ— æœªå¯ç”¨'}
          </span>
        </div>
        <div>
          {recording || systemAudioEnabled ? 
            (recording && systemAudioEnabled ? 
              "æ­£åœ¨å½•éŸ³ä¸­ï¼ŒåŒæ—¶æ•è·æ‚¨å’Œé¢è¯•å®˜çš„å£°éŸ³..." : 
              recording ? "æ­£åœ¨å½•éŸ³ä¸­ï¼Œä»…æ•è·æ‚¨çš„å£°éŸ³" :
              "æ­£åœ¨å½•éŸ³ä¸­ï¼Œä»…æ•è·é¢è¯•å®˜çš„å£°éŸ³"
            ) : 
            "ç‚¹å‡»æŒ‰é’®å¼€å§‹å½•éŸ³ï¼Œå¯åˆ†åˆ«æ§åˆ¶éº¦å…‹é£å’Œç³»ç»ŸéŸ³é¢‘"
          }
        </div>
      </div>
      
      {showTestPanel && (
        <AudioTestPanel onClose={() => setShowTestPanel(false)} />
      )}
    </div>
  );
}