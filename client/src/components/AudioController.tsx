import { useState, useRef, useEffect } from "react";
import { connectASRWebSocket, startSystemAudio, stopSystemAudio, stopWebSocket } from "../api/websocket";
import AudioTestPanel from "./AudioTestPanel";
import AudioLevelMeter from "./AudioLevelMeter";
import { AudioWorkletManager } from "../audio/audioWorkletManager";

interface Props {
  onUserText: (text: string, isPartial?: boolean) => void;
  onInterviewerText: (text: string, isPartial?: boolean) => void;
  sessionId?: string; // ä¼šè¯ID
}

export default function AudioController({ onUserText, onInterviewerText, sessionId = "default" }: Props) {
  const [recording, setRecording] = useState(false);
  const [error, setError] = useState<string>("");
  const [connectionStatus, setConnectionStatus] = useState<string>("æœªè¿æ¥");
  const [systemAudioEnabled, setSystemAudioEnabled] = useState(false);
  const [showTestPanel, setShowTestPanel] = useState(false);
  const [systemStream, setSystemStream] = useState<MediaStream | null>(null);
  // ç”¨æˆ·éº¦å…‹é£ç›¸å…³
  const userWsRef = useRef<WebSocket | null>(null);
  const userStreamRef = useRef<MediaStream | null>(null);
  const userWorkletManagerRef = useRef<AudioWorkletManager | null>(null);
  const userProcessorRef = useRef<ScriptProcessorNode | null>(null); // é™çº§æ¨¡å¼ä½¿ç”¨
  const userAudioContextRef = useRef<AudioContext | null>(null); // é™çº§æ¨¡å¼ä½¿ç”¨
  
  // ç³»ç»ŸéŸ³é¢‘WebSocketè¿æ¥
  const systemWsRef = useRef<WebSocket | null>(null);

  // å¯åŠ¨ç”¨æˆ·éº¦å…‹é£å½•éŸ³
  const startUserAudio = async () => {
    try {
      console.log("ğŸ¤ å¼€å§‹æ•è·ç”¨æˆ·éº¦å…‹é£...");
      
      // è·å–éº¦å…‹é£æƒé™ï¼ˆä¸æµ‹è¯•ä¿æŒä¸€è‡´ï¼‰
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true // ä¸æµ‹è¯•ä¿æŒä¸€è‡´ï¼Œä½¿ç”¨ AGC
        }
      });
      
      userStreamRef.current = stream;
      
      // åˆ›å»ºWebSocketè¿æ¥ï¼ˆæ–°æ¥å£ï¼š/ws/audio/{session_id}/micï¼‰
      userWsRef.current = connectASRWebSocket(sessionId, "mic", {
        onFinal: (text) => {
          onUserText(text, false);
        },
        onPartial: (text) => {
          // éƒ¨åˆ†ç»“æœç”¨äºå®æ—¶æ˜¾ç¤ºï¼ˆæ–œä½“æˆ–ç°è‰²ï¼‰
          onUserText(text, true);
        },
        onInfo: (text) => {
          console.log("[mic] Info:", text);
          if (text.includes("connected")) {
            setConnectionStatus("å·²è¿æ¥ - è¯†åˆ«ä¸­");
          }
        },
        onError: (text) => {
          console.error("[mic] Error:", text);
          setError(text);
        }
      });
      
      // ä½¿ç”¨ AudioWorklet æ›¿ä»£ ScriptProcessor
      // å¦‚æœ AudioWorklet åŠ è½½å¤±è´¥ï¼Œå¯ä»¥é™çº§åˆ° ScriptProcessor
      let workletManager: AudioWorkletManager | null = null;
      try {
        workletManager = new AudioWorkletManager();
        await workletManager.initialize(stream, {
        onAudioFrame: (data, metadata) => {
          // å‘é€éŸ³é¢‘å¸§ï¼ˆå¸¦å…ƒæ•°æ®ï¼‰
          if (userWsRef.current?.readyState === WebSocket.OPEN) {
            try {
              // åˆ›å»ºå¸¦å…ƒæ•°æ®çš„æ¶ˆæ¯
              // æ ¼å¼ï¼šseq(4) + t0(8) + sr(4) + channels(1) + frameCount(4) + rms(4) = 25å­—èŠ‚
              // ä½¿ç”¨ 32 å­—èŠ‚å¯¹é½ï¼Œä¾¿äºåç»­æ‰©å±•
              const header = new ArrayBuffer(32);
              const view = new DataView(header);
              let offset = 0;
              view.setUint32(offset, metadata.seq, true); offset += 4;
              view.setFloat64(offset, metadata.t0, true); offset += 8;
              view.setUint32(offset, metadata.sr, true); offset += 4;
              view.setUint8(offset, metadata.channels); offset += 1;
              view.setUint32(offset, metadata.frameCount, true); offset += 4;
              if (metadata.rms !== undefined) {
                view.setFloat32(offset, metadata.rms, true); offset += 4;
              }
              // offset ç°åœ¨åº”è¯¥æ˜¯ 25ï¼Œå‰©ä½™ 7 å­—èŠ‚ä¸º paddingï¼ˆè‡ªåŠ¨ä¸º 0ï¼‰
              
              // åˆå¹¶ header å’ŒéŸ³é¢‘æ•°æ®
              const combined = new Uint8Array(header.byteLength + data.byteLength);
              combined.set(new Uint8Array(header), 0);
              combined.set(new Uint8Array(data), header.byteLength);
              
              // æ£€æŸ¥ WebSocket ç¼“å†²çŠ¶æ€ï¼ˆé¿å…é˜»å¡ï¼‰
              if (userWsRef.current.bufferedAmount > 1024 * 1024) { // 1MB
                console.warn('[Audio] WebSocket buffer full, dropping frame');
                return;
              }
              
              userWsRef.current.send(combined.buffer);
            } catch (error) {
              console.error('[Audio] Failed to send audio frame:', error);
              // ä¸æŠ›å‡ºé”™è¯¯ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€å¸§
            }
          }
        },
        onError: (error) => {
          console.error("AudioWorklet error:", error);
          setError(`éŸ³é¢‘å¤„ç†é”™è¯¯: ${error.message}`);
        }
      });
      
      userWorkletManagerRef.current = workletManager;
      console.log("âœ… ç”¨æˆ·éº¦å…‹é£å·²å¯åŠ¨ï¼ˆAudioWorkletï¼‰");
      } catch (workletError) {
        console.warn("AudioWorklet åˆå§‹åŒ–å¤±è´¥ï¼Œé™çº§åˆ° ScriptProcessorï¼ˆä¸æµ‹è¯•é€»è¾‘ä¸€è‡´ï¼‰:", workletError);
        // é™çº§åˆ° ScriptProcessorï¼ˆä¸æµ‹è¯•é€»è¾‘å®Œå…¨ä¸€è‡´ï¼‰
        const audioContext = new AudioContext({ sampleRate: 16000 });
        userAudioContextRef.current = audioContext;
        const source = audioContext.createMediaStreamSource(stream);
        const processor = audioContext.createScriptProcessor(4096, 1, 1);
        userProcessorRef.current = processor;
        
        // åˆ›å»ºé™éŸ³çš„ GainNodeï¼ˆScriptProcessor å¿…é¡»è¿æ¥è¾“å‡ºæ‰èƒ½å·¥ä½œï¼‰
        const silentGain = audioContext.createGain();
        silentGain.gain.value = 0;
        processor.connect(silentGain);
        silentGain.connect(audioContext.destination);
        
        processor.onaudioprocess = (event) => {
          if (userWsRef.current?.readyState === WebSocket.OPEN) {
            try {
              const inputData = event.inputBuffer.getChannelData(0);
              // è½¬æ¢ä¸º16ä½PCMï¼ˆä¸æµ‹è¯•é€»è¾‘ä¸€è‡´ï¼‰
              const pcmData = new Int16Array(inputData.length);
              for (let i = 0; i < inputData.length; i++) {
                pcmData[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32768));
              }
              // ç›´æ¥å‘é€ PCM æ•°æ®ï¼ˆæ— å…ƒæ•°æ®å¤´ï¼Œä¸æµ‹è¯•ä¸€è‡´ï¼‰
              userWsRef.current.send(pcmData.buffer);
            } catch (error) {
              console.error('[Audio] ScriptProcessor send error:', error);
            }
          }
        };
        
        source.connect(processor);
        userWorkletManagerRef.current = null; // æ ‡è®°ä½¿ç”¨ ScriptProcessor
        console.log("âœ… ç”¨æˆ·éº¦å…‹é£å·²å¯åŠ¨ï¼ˆScriptProcessor é™çº§æ¨¡å¼ï¼Œä¸æµ‹è¯•ä¸€è‡´ï¼‰");
      }
      
    } catch (err) {
      console.error("ç”¨æˆ·éº¦å…‹é£å¯åŠ¨å¤±è´¥:", err);
      throw new Error("æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®");
    }
  };

  // å¯åŠ¨ç³»ç»ŸéŸ³é¢‘ï¼ˆé€šè¿‡åç«¯ï¼‰
  const startSystemAudioCapture = async () => {
    try {
      console.log("ğŸ”Š å¯åŠ¨åç«¯ç³»ç»ŸéŸ³é¢‘æ•è·...");
      
      // åˆ›å»ºç³»ç»ŸéŸ³é¢‘WebSocketè¿æ¥ï¼ˆæ–°æ¥å£ï¼š/ws/audio/{session_id}/sysï¼‰
      systemWsRef.current = connectASRWebSocket(sessionId, "sys", {
        onFinal: (text) => {
          onInterviewerText(text, false);
        },
        onPartial: (text) => {
          // éƒ¨åˆ†ç»“æœç”¨äºå®æ—¶æ˜¾ç¤º
          onInterviewerText(text, true);
        },
        onInfo: (text) => {
          console.log("[sys] Info:", text);
        },
        onError: (text) => {
          console.error("[sys] Error:", text);
          setError(text);
        }
      });
      
      // ç­‰å¾…WebSocketè¿æ¥å»ºç«‹
      await new Promise((resolve, reject) => {
        if (systemWsRef.current) {
          systemWsRef.current.onopen = resolve;
          systemWsRef.current.onerror = reject;
          // è®¾ç½®è¶…æ—¶
          setTimeout(() => reject(new Error("è¿æ¥è¶…æ—¶")), 5000);
        }
      });
      
      // å¯åŠ¨åç«¯ç³»ç»ŸéŸ³é¢‘æ•è·
      const success = await startSystemAudio(systemWsRef.current!);
      if (!success) {
        throw new Error("åç«¯ç³»ç»ŸéŸ³é¢‘å¯åŠ¨å¤±è´¥");
      }
      
      console.log("âœ… ç³»ç»ŸéŸ³é¢‘å·²å¯åŠ¨");
      
      // ä¸ºäº†æ˜¾ç¤ºéŸ³é¢‘çº§åˆ«ï¼Œæˆ‘ä»¬ä¹Ÿéœ€è¦è·å–ç³»ç»ŸéŸ³é¢‘æµ
      try {
        const systemStream = await navigator.mediaDevices.getDisplayMedia({
          audio: true,
          video: false
        });
        setSystemStream(systemStream);
      } catch (err) {
        console.warn("æ— æ³•è·å–ç³»ç»ŸéŸ³é¢‘æµç”¨äºæ˜¾ç¤º:", err);
      }
      
    } catch (err) {
      console.error("ç³»ç»ŸéŸ³é¢‘å¯åŠ¨å¤±è´¥:", err);
      throw new Error("ç³»ç»ŸéŸ³é¢‘å¯åŠ¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥åç«¯æœåŠ¡");
    }
  };

  // å¯åŠ¨éº¦å…‹é£å½•éŸ³
  const startMic = async () => {
    try {
      setError("");
      console.log("ğŸ¤ å¼€å§‹æ•è·éº¦å…‹é£...");
      
      await startUserAudio();
      
      setConnectionStatus("å·²è¿æ¥ - è¯†åˆ«ä¸­");
      setRecording(true);
      
    } catch (err) {
      console.error("éº¦å…‹é£å¯åŠ¨å¤±è´¥:", err);
      setError(err instanceof Error ? err.message : "éº¦å…‹é£å¯åŠ¨å¤±è´¥");
    }
  };

  // åœæ­¢éº¦å…‹é£å½•éŸ³
  const stopMic = () => {
    console.log("ğŸ›‘ åœæ­¢éº¦å…‹é£å½•éŸ³");
    
    // åœæ­¢ç”¨æˆ·éŸ³é¢‘å¤„ç†ï¼ˆAudioWorklet æˆ– ScriptProcessorï¼‰
    if (userWorkletManagerRef.current) {
      userWorkletManagerRef.current.stop();
      userWorkletManagerRef.current = null;
    }
    
    // æ¸…ç† ScriptProcessor é™çº§æ¨¡å¼
    if (userProcessorRef.current) {
      userProcessorRef.current.disconnect();
      userProcessorRef.current = null;
    }
    
    if (userAudioContextRef.current) {
      userAudioContextRef.current.close();
      userAudioContextRef.current = null;
    }
    
    if (userStreamRef.current) {
      userStreamRef.current.getTracks().forEach(track => track.stop());
      userStreamRef.current = null;
    }
    
    if (userWsRef.current) {
      stopWebSocket(userWsRef.current);
      userWsRef.current = null;
    }
    
    setRecording(false);
    if (!systemAudioEnabled) {
      setConnectionStatus("æœªè¿æ¥");
    }
  };

  // å¯åŠ¨ç³»ç»ŸéŸ³é¢‘
  const startSystem = async () => {
    try {
      setError("");
      console.log("ğŸ”Š å¯åŠ¨ç³»ç»ŸéŸ³é¢‘...");
      
      await startSystemAudioCapture();
      setSystemAudioEnabled(true);
      console.log("âœ… ç³»ç»ŸéŸ³é¢‘å·²å¯åŠ¨");
      
    } catch (err) {
      console.error("ç³»ç»ŸéŸ³é¢‘å¯åŠ¨å¤±è´¥:", err);
      setError(err instanceof Error ? err.message : "ç³»ç»ŸéŸ³é¢‘å¯åŠ¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥åç«¯æœåŠ¡");
    }
  };

  // åœæ­¢ç³»ç»ŸéŸ³é¢‘
  const stopSystem = () => {
    console.log("ğŸ›‘ åœæ­¢ç³»ç»ŸéŸ³é¢‘");
    
    if (systemWsRef.current) {
      stopSystemAudio(systemWsRef.current).then(() => {
        stopWebSocket(systemWsRef.current!);
        systemWsRef.current = null;
      });
    }
    
    if (systemStream) {
      systemStream.getTracks().forEach(track => track.stop());
      setSystemStream(null);
    }
    
    setSystemAudioEnabled(false);
    if (!recording) {
      setConnectionStatus("æœªè¿æ¥");
    }
  };



  // æ¸…ç†èµ„æº
  useEffect(() => {
    return () => {
      if (recording) {
        stopMic();
      }
      if (systemAudioEnabled) {
        stopSystem();
      }
    };
  }, []);

  return (
    <div className="mt-6 flex flex-col gap-4">
      {error && (
        <div className="rounded-xl border border-red-500/30 bg-red-500/10 px-4 py-3 text-sm text-red-200 shadow-inner">
          {error}
        </div>
      )}

      <div className="flex flex-wrap items-center justify-center gap-3">
        <button
          onClick={recording ? stopMic : startMic}
          className={`rounded-xl bg-gradient-to-r px-5 py-2.5 text-sm font-semibold text-white shadow-lg transition duration-200 hover:-translate-y-0.5 focus-visible:outline focus-visible:outline-2 focus-visible:outline-brand-primary/60 ${
            recording
              ? 'from-rose-500 to-rose-600'
              : 'from-emerald-500 to-emerald-600'
          }`}
        >
          {recording ? 'â¹ åœæ­¢éº¦å…‹é£' : 'ğŸ¤ å¼€å§‹éº¦å…‹é£'}
        </button>

        <button
          onClick={systemAudioEnabled ? stopSystem : startSystem}
          className={`rounded-xl bg-gradient-to-r px-5 py-2.5 text-sm font-semibold text-white shadow-lg transition duration-200 hover:-translate-y-0.5 focus-visible:outline focus-visible:outline-2 focus-visible:outline-brand-primary/60 ${
            systemAudioEnabled
              ? 'from-rose-500 to-rose-600'
              : 'from-brand-primary to-brand-secondary'
          }`}
        >
          {systemAudioEnabled ? 'â¹ åœæ­¢ç³»ç»ŸéŸ³é¢‘' : 'ğŸ”Š å¼€å§‹ç³»ç»ŸéŸ³é¢‘'}
        </button>

        <button
          type="button"
          onClick={() => setShowTestPanel(true)}
          className="rounded-xl border border-slate-700 bg-slate-900/70 px-5 py-2.5 text-sm font-semibold text-slate-200 shadow-lg transition duration-200 hover:-translate-y-0.5 hover:border-brand-primary/60 hover:text-brand-primary focus-visible:outline focus-visible:outline-2 focus-visible:outline-brand-primary/60"
        >
          ğŸ§ éŸ³é¢‘æµ‹è¯•
        </button>
      </div>

      {(recording || systemAudioEnabled) && (
        <div className="rounded-2xl border border-slate-800 bg-slate-900/70 p-4">
          <div className="mb-3 text-center text-sm font-semibold text-slate-200">
            ğŸ“Š å®æ—¶éŸ³é¢‘ç›‘æ§
          </div>

          {recording && (
            <AudioLevelMeter
              stream={userStreamRef.current}
              label="ğŸ¤ éº¦å…‹é£"
              color="#10b981"
              isActive={recording}
            />
          )}

          {systemAudioEnabled && (
            <AudioLevelMeter
              stream={systemStream}
              label="ğŸ”Š ç³»ç»ŸéŸ³é¢‘"
              color="#8b5cf6"
              isActive={systemAudioEnabled}
            />
          )}
        </div>
      )}

      <div className="text-center text-xs text-slate-400">
        <div className="mb-1">
          çŠ¶æ€:
          <span
            className={`ml-1 font-semibold ${
              connectionStatus.includes('å·²è¿æ¥')
                ? 'text-emerald-400'
                : connectionStatus.includes('é”™è¯¯')
                  ? 'text-rose-400'
                  : 'text-amber-400'
            }`}
          >
            {connectionStatus}
          </span>
        </div>
        <div className="mb-1">
          éº¦å…‹é£:
          <span className={`ml-1 font-semibold ${recording ? 'text-emerald-400' : 'text-amber-400'}`}>
            {recording ? 'âœ“ å·²å¯ç”¨' : 'âœ— æœªå¯ç”¨'}
          </span>
        </div>
        <div className="mb-2">
          ç³»ç»ŸéŸ³é¢‘:
          <span className={`ml-1 font-semibold ${systemAudioEnabled ? 'text-emerald-400' : 'text-amber-400'}`}>
            {systemAudioEnabled ? 'âœ“ å·²å¯ç”¨' : 'âœ— æœªå¯ç”¨'}
          </span>
        </div>
        <div className="text-slate-500">
          {recording || systemAudioEnabled
            ? recording && systemAudioEnabled
              ? 'æ­£åœ¨å½•éŸ³ä¸­ï¼ŒåŒæ—¶æ•è·æ‚¨å’Œé¢è¯•å®˜çš„å£°éŸ³...'
              : recording
                ? 'æ­£åœ¨å½•éŸ³ä¸­ï¼Œä»…æ•è·æ‚¨çš„å£°éŸ³'
                : 'æ­£åœ¨å½•éŸ³ä¸­ï¼Œä»…æ•è·é¢è¯•å®˜çš„å£°éŸ³'
            : 'ç‚¹å‡»æŒ‰é’®å¼€å§‹å½•éŸ³ï¼Œå¯åˆ†åˆ«æ§åˆ¶éº¦å…‹é£å’Œç³»ç»ŸéŸ³é¢‘'}
        </div>
      </div>

      {showTestPanel && (
        <AudioTestPanel onClose={() => setShowTestPanel(false)} />
      )}
    </div>
  );
}